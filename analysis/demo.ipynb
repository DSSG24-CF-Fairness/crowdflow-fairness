{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create folder named experiment#1 in processed data, outputs and analysis\n",
    "\n",
    "# Get data for flow, tessellations, demographics and geographical boundary of WA\n",
    "\n",
    "# Split data into training and test - create four files: Flows for train and test, region indices for train and test\n",
    "# Save these files in processed data folder \n",
    "# TODO Create visualization and save to outputs of experiement\n",
    "\n",
    "# Biased sampling on the training data to create two biased datasets - save in processed data folder for experiment1 \n",
    "\n",
    "# Run single constrained gravity model on biased training data and original data to create three models \n",
    "# Run trained models on unbiased test data and create generated flows in outputs \n",
    "\n",
    "# Use generated flows from outputs and test true labels from processed data to create fairness metrics and visualizations\n",
    "# Save this in outputs - fairness.json and fairness.png (for each model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# USE ML TUTORIAL ENVN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/apoorvasheera/anaconda3/envs/MLTutorial/lib/python3.11/site-packages/IPython/core/interactiveshell.py:3505: FutureWarning: The `op` parameter is deprecated and will be removed in a future release. Please use the `predicate` parameter instead.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "'left_df' should be GeoDataFrame, got <class 'pandas.core.frame.DataFrame'>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 22\u001b[0m\n\u001b[1;32m     19\u001b[0m grid \u001b[38;5;241m=\u001b[39m create_grid(washington\u001b[38;5;241m.\u001b[39munary_union, \u001b[38;5;241m25\u001b[39m)\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# Split the data into train and test sets\u001b[39;00m\n\u001b[0;32m---> 22\u001b[0m train_output, test_output \u001b[38;5;241m=\u001b[39m \u001b[43mflow_train_test_split\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtessellation_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeatures_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexperiment_id\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mexperiment_id\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m# train_geoids = set(train_output['census_tracts_geoids'].explode())\u001b[39;00m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m# print(len(train_geoids))\u001b[39;00m\n\u001b[1;32m     26\u001b[0m \n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m# vis\u001b[39;00m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;66;03m# plot_grid_and_census_tracts(grid, tessellation_df, train_output, test_output)\u001b[39;00m\n\u001b[1;32m     30\u001b[0m filter_train_test_data(flow_df, tessellation_df, features_df, train_output, test_output, experiment_id \u001b[38;5;241m=\u001b[39m experiment_id)\n",
      "File \u001b[0;32m~/Documents/DSSG/Crowd Flow/crowdflow-fairness/preprocessing/train_test_processing.py:104\u001b[0m, in \u001b[0;36mflow_train_test_split\u001b[0;34m(tessellation_df, features_df, grid, experiment_id, crs)\u001b[0m\n\u001b[1;32m     90\u001b[0m census_tracts_gdf \u001b[38;5;241m=\u001b[39m tessellation_df[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGEOID\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlng\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlat\u001b[39m\u001b[38;5;124m'\u001b[39m]]\n\u001b[1;32m     93\u001b[0m \u001b[38;5;66;03m# # Create DataFrame for census tracts with geoids, longitudes, and latitudes\u001b[39;00m\n\u001b[1;32m     94\u001b[0m \u001b[38;5;66;03m# geo_o = flow_df[['geoid_o', 'lng_o', 'lat_o']].rename(columns={'geoid_o': 'geoid', 'lng_o': 'lng', 'lat_o': 'lat'})\u001b[39;00m\n\u001b[1;32m     95\u001b[0m \u001b[38;5;66;03m# geo_d = flow_df[['geoid_d', 'lng_d', 'lat_d']].rename(columns={'geoid_d': 'geoid', 'lng_d': 'lng', 'lat_d': 'lat'})\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    102\u001b[0m \n\u001b[1;32m    103\u001b[0m \u001b[38;5;66;03m# Match census tracts with grid cells\u001b[39;00m\n\u001b[0;32m--> 104\u001b[0m matched_gdf \u001b[38;5;241m=\u001b[39m \u001b[43mgpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcensus_tracts_gdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrid\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mgeometry\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mregion_index\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mleft\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mwithin\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    105\u001b[0m matched_gdf \u001b[38;5;241m=\u001b[39m matched_gdf\u001b[38;5;241m.\u001b[39mdrop(columns\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgeometry\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mfillna(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mastype({\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mregion_index\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mInt64\u001b[39m\u001b[38;5;124m'\u001b[39m})\n\u001b[1;32m    106\u001b[0m matched_gdf \u001b[38;5;241m=\u001b[39m matched_gdf[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgeoid\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mregion_index\u001b[39m\u001b[38;5;124m'\u001b[39m]]\n",
      "File \u001b[0;32m~/anaconda3/envs/MLTutorial/lib/python3.11/site-packages/geopandas/tools/sjoin.py:119\u001b[0m, in \u001b[0;36msjoin\u001b[0;34m(left_df, right_df, how, predicate, lsuffix, rsuffix, **kwargs)\u001b[0m\n\u001b[1;32m    116\u001b[0m     first \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28miter\u001b[39m(kwargs\u001b[38;5;241m.\u001b[39mkeys()))\n\u001b[1;32m    117\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msjoin() got an unexpected keyword argument \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfirst\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 119\u001b[0m \u001b[43m_basic_checks\u001b[49m\u001b[43m(\u001b[49m\u001b[43mleft_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mright_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhow\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlsuffix\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrsuffix\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    121\u001b[0m indices \u001b[38;5;241m=\u001b[39m _geom_predicate_query(left_df, right_df, predicate)\n\u001b[1;32m    123\u001b[0m joined \u001b[38;5;241m=\u001b[39m _frame_join(indices, left_df, right_df, how, lsuffix, rsuffix)\n",
      "File \u001b[0;32m~/anaconda3/envs/MLTutorial/lib/python3.11/site-packages/geopandas/tools/sjoin.py:147\u001b[0m, in \u001b[0;36m_basic_checks\u001b[0;34m(left_df, right_df, how, lsuffix, rsuffix)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Checks the validity of join input parameters.\u001b[39;00m\n\u001b[1;32m    130\u001b[0m \n\u001b[1;32m    131\u001b[0m \u001b[38;5;124;03m`how` must be one of the valid options.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[38;5;124;03m    right index suffix\u001b[39;00m\n\u001b[1;32m    145\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    146\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(left_df, GeoDataFrame):\n\u001b[0;32m--> 147\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    148\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mleft_df\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m should be GeoDataFrame, got \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mtype\u001b[39m(left_df))\n\u001b[1;32m    149\u001b[0m     )\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(right_df, GeoDataFrame):\n\u001b[1;32m    152\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    153\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mright_df\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m should be GeoDataFrame, got \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mtype\u001b[39m(right_df))\n\u001b[1;32m    154\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: 'left_df' should be GeoDataFrame, got <class 'pandas.core.frame.DataFrame'>"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sys.path.append(os.path.abspath('../preprocessing'))\n",
    "from train_test_processing import * \n",
    "sys.path.append(os.path.abspath('../preprocessing'))\n",
    "from train_test_split_vis import * \n",
    "\n",
    "experiment_id = '1'\n",
    "\n",
    "# washington = load_state_or_county_data('../data/WA/boundary.geojson')\n",
    "washington = load_state_or_county_data('../data/WA/WA_State_Boundary.geojson')\n",
    "flow_df = pd.read_csv('../data/WA/flow.csv')\n",
    "features_df = pd.read_csv('../data/WA/features.csv')\n",
    "tessellation_df = load_state_or_county_data('../data/WA/tessellation_wpop.geojson')\n",
    "# grid = create_grid(washington.unary_union, 25, washington.crs)\n",
    "grid = create_grid(washington.unary_union, 25)\n",
    "\n",
    "# Split the data into train and test sets\n",
    "train_output, test_output = flow_train_test_split(tessellation_df, features_df, grid, experiment_id = experiment_id)\n",
    "\n",
    "# train_geoids = set(train_output['census_tracts_geoids'].explode())\n",
    "# print(len(train_geoids))\n",
    "\n",
    "# vis\n",
    "# plot_grid_and_census_tracts(grid, tessellation_df, train_output, test_output)\n",
    "\n",
    "filter_train_test_data(flow_df, tessellation_df, features_df, train_output, test_output, experiment_id = experiment_id)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/apoorvasheera/Documents/DSSG/Crowd Flow/crowdflow-fairness/preprocessing/biased_sampling.py:28: FutureWarning: Passing 'suffixes' which cause duplicate columns {'geoid_x'} in the result is deprecated and will raise a MergeError in a future version.\n",
      "  destination_merge = pd.merge(destination_merge, features[['geoid', 'total_population']], how='left', left_on='destination', right_on='geoid')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns with missing data and their count:\n",
      "origin               0\n",
      "destination          0\n",
      "demographic_o    14031\n",
      "demographic_d    15057\n",
      "population_o     14031\n",
      "population_d     15057\n",
      "flow                 0\n",
      "dtype: int64\n",
      "Missing data diagnostic saved to ../outputs/1/train/missing_data_diagnosis.csv\n",
      "(30023, 7)\n",
      "Saved adjusted flows to ../processed_data/1/train/flows/svi/1_ascending_biased_flow.csv\n",
      "Columns with missing data and their count:\n",
      "origin               0\n",
      "destination          0\n",
      "demographic_o    14031\n",
      "demographic_d    15057\n",
      "population_o     14031\n",
      "population_d     15057\n",
      "flow                 0\n",
      "dtype: int64\n",
      "Missing data diagnostic saved to ../outputs/1/train/missing_data_diagnosis.csv\n",
      "(30023, 7)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/apoorvasheera/Documents/DSSG/Crowd Flow/crowdflow-fairness/preprocessing/biased_sampling.py:28: FutureWarning: Passing 'suffixes' which cause duplicate columns {'geoid_x'} in the result is deprecated and will raise a MergeError in a future version.\n",
      "  destination_merge = pd.merge(destination_merge, features[['geoid', 'total_population']], how='left', left_on='destination', right_on='geoid')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved adjusted flows to ../processed_data/1/train/flows/svi/1_descending_biased_flow.csv\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "experiment_id = \"1\"\n",
    "\n",
    "sys.path.append(os.path.abspath('../preprocessing'))\n",
    "from biased_sampling import *\n",
    "\n",
    "features_df = pd.read_csv(\"../processed_data/1/train/train_features.csv\")\n",
    "train_flows_df = pd.read_csv(\"../processed_data/1/train/flows/train_flow.csv\")\n",
    "demographics_df = pd.read_csv(\"../data/WA/demographics.csv\")\n",
    "\n",
    "\n",
    "calculate_biased_flow(features_df, demographics_df, train_flows_df, demographic_column_name='svi', method=1, order=\"ascending\", sampling=False, experiment_id=experiment_id, bias_factor=0.5)\n",
    "calculate_biased_flow(features_df, demographics_df, train_flows_df, demographic_column_name='svi', method=1, order=\"descending\", sampling=False, experiment_id=experiment_id, bias_factor=0.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here change environement to one with scikit-mobility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath('../models'))\n",
    "from gravity import *\n",
    "\n",
    "experiment_id = \"1\"\n",
    "\n",
    "tessellation_train = gpd.read_file(\"../processed_data/1/train/train_tessellation.geojson\")\n",
    "tessellation_test = gpd.read_file(\"../processed_data/1/test/test_tessellation.geojson\")\n",
    "\n",
    "gravity = grav_Model(tessellation_train, tessellation_test, \"../processed_data/1/train/flows/train_flow.csv\",\"../processed_data/1/test/flows/test_flow.csv\", \"gravity_singly_constrained\", 'flows', experiment_id=experiment_id)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracts = gpd.read_file()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GEOID</th>\n",
       "      <th>XCOORD</th>\n",
       "      <th>YCOORD</th>\n",
       "      <th>total_population</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>53003960100</td>\n",
       "      <td>2.478878e+06</td>\n",
       "      <td>316229.093061</td>\n",
       "      <td>4320</td>\n",
       "      <td>POLYGON ((2407498.76364 263743.17398, 2407478....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>53003960300</td>\n",
       "      <td>2.510151e+06</td>\n",
       "      <td>414911.963972</td>\n",
       "      <td>3633</td>\n",
       "      <td>POLYGON ((2504540.37717 416766.54412, 2504886....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>53003960400</td>\n",
       "      <td>2.505962e+06</td>\n",
       "      <td>412445.800829</td>\n",
       "      <td>2517</td>\n",
       "      <td>POLYGON ((2502838.27233 412941.39943, 2502910....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53003960500</td>\n",
       "      <td>2.510481e+06</td>\n",
       "      <td>410373.766615</td>\n",
       "      <td>3517</td>\n",
       "      <td>POLYGON ((2507857.92970 408364.67024, 2507893....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>53003960600</td>\n",
       "      <td>2.507962e+06</td>\n",
       "      <td>405277.944477</td>\n",
       "      <td>3894</td>\n",
       "      <td>POLYGON ((2502417.95942 404700.62798, 2502406....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>576</th>\n",
       "      <td>53077002101</td>\n",
       "      <td>1.757987e+06</td>\n",
       "      <td>396967.615952</td>\n",
       "      <td>2297</td>\n",
       "      <td>POLYGON ((1716307.79591 387056.62897, 1716307....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>577</th>\n",
       "      <td>53077002801</td>\n",
       "      <td>1.585170e+06</td>\n",
       "      <td>449477.275913</td>\n",
       "      <td>5865</td>\n",
       "      <td>POLYGON ((1559608.17932 441157.52938, 1559611....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>578</th>\n",
       "      <td>53077940002</td>\n",
       "      <td>1.671599e+06</td>\n",
       "      <td>376587.366439</td>\n",
       "      <td>4731</td>\n",
       "      <td>POLYGON ((1634622.09067 368811.57790, 1634623....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>579</th>\n",
       "      <td>53077940005</td>\n",
       "      <td>1.686814e+06</td>\n",
       "      <td>379232.681614</td>\n",
       "      <td>4727</td>\n",
       "      <td>POLYGON ((1681785.22522 381158.56677, 1681814....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>580</th>\n",
       "      <td>53077940006</td>\n",
       "      <td>1.689108e+06</td>\n",
       "      <td>383246.391621</td>\n",
       "      <td>4614</td>\n",
       "      <td>POLYGON ((1682577.97845 386516.43742, 1683158....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>581 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           GEOID        XCOORD         YCOORD  total_population  \\\n",
       "0    53003960100  2.478878e+06  316229.093061              4320   \n",
       "1    53003960300  2.510151e+06  414911.963972              3633   \n",
       "2    53003960400  2.505962e+06  412445.800829              2517   \n",
       "3    53003960500  2.510481e+06  410373.766615              3517   \n",
       "4    53003960600  2.507962e+06  405277.944477              3894   \n",
       "..           ...           ...            ...               ...   \n",
       "576  53077002101  1.757987e+06  396967.615952              2297   \n",
       "577  53077002801  1.585170e+06  449477.275913              5865   \n",
       "578  53077940002  1.671599e+06  376587.366439              4731   \n",
       "579  53077940005  1.686814e+06  379232.681614              4727   \n",
       "580  53077940006  1.689108e+06  383246.391621              4614   \n",
       "\n",
       "                                              geometry  \n",
       "0    POLYGON ((2407498.76364 263743.17398, 2407478....  \n",
       "1    POLYGON ((2504540.37717 416766.54412, 2504886....  \n",
       "2    POLYGON ((2502838.27233 412941.39943, 2502910....  \n",
       "3    POLYGON ((2507857.92970 408364.67024, 2507893....  \n",
       "4    POLYGON ((2502417.95942 404700.62798, 2502406....  \n",
       "..                                                 ...  \n",
       "576  POLYGON ((1716307.79591 387056.62897, 1716307....  \n",
       "577  POLYGON ((1559608.17932 441157.52938, 1559611....  \n",
       "578  POLYGON ((1634622.09067 368811.57790, 1634623....  \n",
       "579  POLYGON ((1681785.22522 381158.56677, 1681814....  \n",
       "580  POLYGON ((1682577.97845 386516.43742, 1683158....  \n",
       "\n",
       "[581 rows x 5 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tessellation_train = gpd.read_file(\"../processed_data/1/train/train_tessellation.geojson\")\n",
    "tessellation_test = gpd.read_file(\"../processed_data/1/test/test_tessellation.geojson\")\n",
    "\n",
    "tessellation_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GEOID</th>\n",
       "      <th>XCOORD</th>\n",
       "      <th>YCOORD</th>\n",
       "      <th>total_population</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>53001950100</td>\n",
       "      <td>2.164853e+06</td>\n",
       "      <td>671104.074676</td>\n",
       "      <td>2606</td>\n",
       "      <td>POLYGON ((2018032.07503 696360.32890, 2018022....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>53001950200</td>\n",
       "      <td>2.138151e+06</td>\n",
       "      <td>585491.984120</td>\n",
       "      <td>1763</td>\n",
       "      <td>POLYGON ((2019612.57190 579263.24944, 2019614....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>53001950400</td>\n",
       "      <td>1.974047e+06</td>\n",
       "      <td>549486.692609</td>\n",
       "      <td>3144</td>\n",
       "      <td>POLYGON ((1970740.91951 547174.93228, 1970739....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53001950500</td>\n",
       "      <td>1.975942e+06</td>\n",
       "      <td>541548.994721</td>\n",
       "      <td>5660</td>\n",
       "      <td>POLYGON ((1968357.47234 536445.67382, 1968376....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>53003960200</td>\n",
       "      <td>2.456469e+06</td>\n",
       "      <td>391335.882695</td>\n",
       "      <td>4755</td>\n",
       "      <td>POLYGON ((2417940.12672 381783.84509, 2417932....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>569</th>\n",
       "      <td>53077003100</td>\n",
       "      <td>1.619895e+06</td>\n",
       "      <td>500397.085193</td>\n",
       "      <td>5151</td>\n",
       "      <td>POLYGON ((1594373.54961 510882.28934, 1594425....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>570</th>\n",
       "      <td>53077003200</td>\n",
       "      <td>1.630376e+06</td>\n",
       "      <td>478912.391508</td>\n",
       "      <td>6851</td>\n",
       "      <td>POLYGON ((1624779.14869 474582.53222, 1624781....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>571</th>\n",
       "      <td>53077003400</td>\n",
       "      <td>1.622740e+06</td>\n",
       "      <td>482230.093423</td>\n",
       "      <td>4934</td>\n",
       "      <td>POLYGON ((1611534.01258 483165.92967, 1611581....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>572</th>\n",
       "      <td>53077940001</td>\n",
       "      <td>1.625990e+06</td>\n",
       "      <td>393922.733054</td>\n",
       "      <td>6289</td>\n",
       "      <td>POLYGON ((1592154.02354 406573.50909, 1592189....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>573</th>\n",
       "      <td>53077940003</td>\n",
       "      <td>1.548367e+06</td>\n",
       "      <td>333489.391023</td>\n",
       "      <td>3542</td>\n",
       "      <td>POLYGON ((1382245.89172 370618.03304, 1382264....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>574 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           GEOID        XCOORD         YCOORD  total_population  \\\n",
       "0    53001950100  2.164853e+06  671104.074676              2606   \n",
       "1    53001950200  2.138151e+06  585491.984120              1763   \n",
       "2    53001950400  1.974047e+06  549486.692609              3144   \n",
       "3    53001950500  1.975942e+06  541548.994721              5660   \n",
       "4    53003960200  2.456469e+06  391335.882695              4755   \n",
       "..           ...           ...            ...               ...   \n",
       "569  53077003100  1.619895e+06  500397.085193              5151   \n",
       "570  53077003200  1.630376e+06  478912.391508              6851   \n",
       "571  53077003400  1.622740e+06  482230.093423              4934   \n",
       "572  53077940001  1.625990e+06  393922.733054              6289   \n",
       "573  53077940003  1.548367e+06  333489.391023              3542   \n",
       "\n",
       "                                              geometry  \n",
       "0    POLYGON ((2018032.07503 696360.32890, 2018022....  \n",
       "1    POLYGON ((2019612.57190 579263.24944, 2019614....  \n",
       "2    POLYGON ((1970740.91951 547174.93228, 1970739....  \n",
       "3    POLYGON ((1968357.47234 536445.67382, 1968376....  \n",
       "4    POLYGON ((2417940.12672 381783.84509, 2417932....  \n",
       "..                                                 ...  \n",
       "569  POLYGON ((1594373.54961 510882.28934, 1594425....  \n",
       "570  POLYGON ((1624779.14869 474582.53222, 1624781....  \n",
       "571  POLYGON ((1611534.01258 483165.92967, 1611581....  \n",
       "572  POLYGON ((1592154.02354 406573.50909, 1592189....  \n",
       "573  POLYGON ((1382245.89172 370618.03304, 1382264....  \n",
       "\n",
       "[574 rows x 5 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tessellation_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing geoids have been saved to ../processed_data/1/missing_geoids_tessellation.csv.\n"
     ]
    }
   ],
   "source": [
    "# Load tessellation\n",
    "tessellation_train = gpd.read_file(\"../processed_data/1/train/train_tessellation.geojson\")\n",
    "tessellation_test = gpd.read_file(\"../processed_data/1/test/test_tessellation.geojson\")\n",
    "\n",
    "# Load flow data\n",
    "train_flow = pd.read_csv(\"../processed_data/1/train/flows/train_flow.csv\")\n",
    "test_flow = pd.read_csv(\"../processed_data/1/test/flows/test_flow.csv\")\n",
    "\n",
    "# Extract unique geoids from flow data\n",
    "train_geoids = set(train_flow['origin'].unique()).union(set(train_flow['destination'].unique()))\n",
    "test_geoids = set(test_flow['origin'].unique()).union(set(test_flow['destination'].unique()))\n",
    "\n",
    "# Extract unique geoids from tessellation data\n",
    "tessellation_train_geoids = set(tessellation_train['GEOID'].unique())\n",
    "tessellation_test_geoids = set(tessellation_test['GEOID'].unique())\n",
    "\n",
    "# Identify missing geoids\n",
    "missing_train_geoids = list(train_geoids - tessellation_train_geoids)\n",
    "missing_test_geoids = list(test_geoids - tessellation_test_geoids)\n",
    "\n",
    "# Combine missing geoids and identify if from train or test\n",
    "missing_geoids_df = pd.DataFrame({\n",
    "    'GEOID': missing_train_geoids + missing_test_geoids,\n",
    "    'Dataset': ['Train'] * len(missing_train_geoids) + ['Test'] * len(missing_test_geoids)\n",
    "})\n",
    "\n",
    "# Save to CSV\n",
    "output_path = \"../processed_data/1/missing_geoids_tessellation.csv\"\n",
    "missing_geoids_df.to_csv(output_path, index=False)\n",
    "print(f\"Missing geoids have been saved to {output_path}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output path for flow_path: ../outputs/1/synthetic_flows.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "flow_file_location = \"../processed_data/1/train/flows/train_flows.csv\"\n",
    "path_parts = flow_file_location.split(os.sep)\n",
    "filename = path_parts[-1]\n",
    "\n",
    "flow_dir_index = path_parts.index('flows') + 1\n",
    "subdirectory = os.sep.join(path_parts[flow_dir_index:-1])\n",
    "if subdirectory:\n",
    "    # Create output filename for structured subdirectory cases\n",
    "    new_filename = filename.replace('.csv', '_synthetic_flows.csv')\n",
    "    output_path = os.path.join('..', 'outputs', experiment_id, subdirectory, new_filename)\n",
    "else:\n",
    "    # Create output filename for general cases without subdirectory\n",
    "    output_path = os.path.join('..', 'outputs', experiment_id, 'synthetic_flows.csv')\n",
    "\n",
    "\n",
    "# # Example usage:\n",
    "# flow_path_1 = '../processed_data/experiment_1/train/flows/svi/1_ascending_biased_flows.csv'\n",
    "# flow_path_2 = '../processed_data/experiment_1/train/flows/train_flows.csv'\n",
    "\n",
    "# output_path_1 = create_output_path(flow_path_1)\n",
    "# output_path_2 = create_output_path(flow_path_2)\n",
    "\n",
    "print(\"Output path for flow_path:\", output_path)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MLTutorial",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
