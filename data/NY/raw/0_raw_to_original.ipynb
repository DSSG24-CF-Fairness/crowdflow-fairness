{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-05T07:42:26.791781Z",
     "start_time": "2024-12-05T07:42:26.741787Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import json\n",
    "import shutil\n",
    "import os\n",
    "from shapely.geometry import mapping\n",
    "import tqdm"
   ],
   "id": "5364fa927f4e2f12",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 1. Convert raw population file to population.csv",
   "id": "9a6474c1b7aa32d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-23T22:56:29.401883Z",
     "start_time": "2024-11-23T22:56:29.353196Z"
    }
   },
   "cell_type": "code",
   "source": [
    "file_path = 'DECENNIALDHC2020.P1_population/DECENNIALDHC2020.P1-Data.csv'\n",
    "raw_population = pd.read_csv(file_path)\n",
    "\n",
    "# Remove the prefix '1400000US' from the GEO_ID column\n",
    "raw_population['GEO_ID'] = raw_population['GEO_ID'].str.replace('1400000US', '', regex=False)\n",
    "raw_population = raw_population[raw_population['GEO_ID'] != 'Geography']\n",
    "\n",
    "# Rename columns\n",
    "raw_population = raw_population.rename(columns={\n",
    "    'NAME': 'label',\n",
    "    'GEO_ID': 'geoid',\n",
    "    'P1_001N': 'total_population'\n",
    "})\n",
    "\n",
    "raw_population = raw_population[['label', 'geoid', 'total_population']]\n",
    "\n",
    "\n",
    "output_file_path = 'population.csv'\n",
    "raw_population.to_csv(output_file_path, index=False)\n",
    "\n",
    "print(f\"Population data saved to {output_file_path}\")"
   ],
   "id": "3264dbf489082524",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Population data saved to population.csv\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 2. Combining shapefile and population data into tessellation.geojson",
   "id": "69e72247a7c80c62"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-23T22:56:38.604212Z",
     "start_time": "2024-11-23T22:56:30.958141Z"
    }
   },
   "cell_type": "code",
   "source": [
    "shapefile_path = \"tl_2020_36_tract20/tl_2020_36_tract20.shp\"\n",
    "gdf = gpd.read_file(shapefile_path)\n",
    "gdf[\"GEOID\"] = gdf[\"GEOID20\"].astype(str)\n",
    "population_csv_path = \"population.csv\"\n",
    "population_df = pd.read_csv(population_csv_path)\n",
    "population_df[\"geoid\"] = population_df[\"geoid\"].astype(str)\n",
    "population_df.rename(columns={\"geoid\": \"GEOID\"}, inplace=True)\n",
    "gdf = gdf.merge(population_df[[\"GEOID\", \"total_population\"]], on=\"GEOID\", how=\"left\")\n",
    "\n",
    "geojson = {\n",
    "    \"type\": \"FeatureCollection\",\n",
    "    \"features\": []\n",
    "}\n",
    "\n",
    "# Iterate through the rows of the GeoDataFrame and populate the GeoJSON features\n",
    "for _, row in gdf.iterrows():\n",
    "    feature = {\n",
    "        \"type\": \"Feature\",\n",
    "        \"properties\": {\n",
    "            \"GEOID\": row[\"GEOID\"],\n",
    "            \"lng\": float(row[\"INTPTLON20\"]),\n",
    "            \"lat\": float(row[\"INTPTLAT20\"]),\n",
    "            \"total_population\": row[\"total_population\"]\n",
    "        },\n",
    "        \"geometry\": mapping(row[\"geometry\"])\n",
    "    }\n",
    "    geojson[\"features\"].append(feature)\n",
    "\n",
    "output_path = 'tessellation_wip.geojson'\n",
    "with open(output_path, 'w') as f:\n",
    "    json.dump(geojson, f, indent=2)\n",
    "\n",
    "print(f\"GeoJSON file saved to {output_path}\")"
   ],
   "id": "e1f83398cad633aa",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GeoJSON file saved to tessellation_wip.geojson\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-23T22:56:40.906468Z",
     "start_time": "2024-11-23T22:56:40.845469Z"
    }
   },
   "cell_type": "code",
   "source": [
    "source = \"tessellation_wip.geojson\"\n",
    "destination = \"../tessellation.geojson\"\n",
    "shutil.copy(source, destination)\n",
    "\n",
    "print(f\"Tessellation copied from {source} to {destination}\")"
   ],
   "id": "562fffb57019a480",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tessellation copied from tessellation_wip.geojson to ../tessellation.geojson\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 3. Mapping geoids in flow.csv to polygon geoids in tessellation.geojson",
   "id": "6c01ffaed64c1d67"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-23T23:06:52.404422Z",
     "start_time": "2024-11-23T22:56:42.734100Z"
    }
   },
   "cell_type": "code",
   "source": [
    "flow = pd.read_csv(\"flow_original.csv\")\n",
    "tessellation = gpd.read_file(\"tessellation_wip.geojson\")\n",
    "\n",
    "# add columns to the tessellation dataframe callled new_geoid_o and new_geoid_d\n",
    "flow[\"new_geoid_o\"] = None\n",
    "flow[\"new_geoid_d\"] = None\n",
    "from shapely.geometry import Point\n",
    "\n",
    "points_sets = set()\n",
    "progress_bar = tqdm.tqdm_notebook(total=len(flow))\n",
    "for i, row in flow.iterrows():\n",
    "    progress_bar.update(1)\n",
    "    points_sets.add((row[\"lng_o\"], row[\"lat_o\"]))\n",
    "    points_sets.add((row[\"lng_d\"], row[\"lat_d\"]))\n",
    "\n",
    "\n",
    "points_to_new_geoid_mapping = {}\n",
    "for pos in tqdm.tqdm_notebook(points_sets):\n",
    "    for j, standard_row in tessellation.iterrows():\n",
    "        if standard_row[\"geometry\"].contains(Point(pos)):\n",
    "            points_to_new_geoid_mapping[pos] = standard_row[\"GEOID\"]\n",
    "            break\n",
    "\n",
    "progress = 0\n",
    "progress_bar = tqdm.tqdm_notebook(total=len(flow))\n",
    "for i, row in flow.iterrows():\n",
    "    progress_bar.update(1)\n",
    "    lng_o = row[\"lng_o\"]\n",
    "    lat_o = row[\"lat_o\"]\n",
    "    geoid_o_old = str(row[\"geoid_o\"])\n",
    "    lng_d = row[\"lng_d\"]\n",
    "    lat_d = row[\"lat_d\"]\n",
    "    geoid_d_old = str(row[\"geoid_d\"])\n",
    "    \n",
    "    if (lng_o, lat_o) in points_to_new_geoid_mapping:\n",
    "        flow.at[i, \"new_geoid_o\"] = points_to_new_geoid_mapping[(lng_o, lat_o)]\n",
    "    if (lng_d, lat_d) in points_to_new_geoid_mapping:\n",
    "        flow.at[i, \"new_geoid_d\"] = points_to_new_geoid_mapping[(lng_d, lat_d)]\n",
    "\n",
    "flow.to_csv('flow_GEOIDadjusted.csv', index=False)\n"
   ],
   "id": "8efec4695af0f35b",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kiki\\AppData\\Local\\Temp\\ipykernel_16152\\2993260289.py:10: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  progress_bar = tqdm.tqdm_notebook(total=len(flow))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "  0%|          | 0/650260 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0a2256824b3c45bcb5bda0462997fb35"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kiki\\AppData\\Local\\Temp\\ipykernel_16152\\2993260289.py:18: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  for pos in tqdm.tqdm_notebook(points_sets):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "  0%|          | 0/4894 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "160cfbad4d5842c792603c7ef75624f8"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kiki\\AppData\\Local\\Temp\\ipykernel_16152\\2993260289.py:25: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  progress_bar = tqdm.tqdm_notebook(total=len(flow))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "  0%|          | 0/650260 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "02379e7cb985478ba9a22a9c0f11d54b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-05T07:59:21.413790Z",
     "start_time": "2024-12-05T07:58:59.019221Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "flow_adjusted = pd.read_csv('flow_GEOIDadjusted.csv')\n",
    "\n",
    "old_to_new_geoid_mapping = defaultdict(set)\n",
    "for i, row in flow_adjusted.iterrows():\n",
    "    try:\n",
    "        geoid_o_old = str(int(row[\"geoid_o\"]))\n",
    "        geoid_o_new = str(int(row[\"new_geoid_o\"]))\n",
    "        old_to_new_geoid_mapping[geoid_o_old].add(geoid_o_new)\n",
    "    except:\n",
    "        old_to_new_geoid_mapping[\"NAN\"].add((str(row[\"geoid_o\"]), str(row[\"new_geoid_o\"])))\n",
    "    \n",
    "    try:\n",
    "        geoid_d_old = str(int(row[\"geoid_d\"]))\n",
    "        geoid_d_new = str(int(row[\"new_geoid_d\"]))\n",
    "        old_to_new_geoid_mapping[geoid_d_old].add(geoid_d_new)\n",
    "    except:\n",
    "        old_to_new_geoid_mapping[\"NAN\"].add((str(row[\"geoid_d\"]), str(row[\"new_geoid_d\"])))\n",
    "        \n",
    "old_to_new_geoid_mapping_sorted = sorted(list(old_to_new_geoid_mapping.items()), key=lambda x: -len(x))\n",
    "\n",
    "unique_counter = 0\n",
    "diff_counter = 0\n",
    "\n",
    "for old, new in old_to_new_geoid_mapping_sorted:\n",
    "    if len(new)!=1:\n",
    "        print(old, new)\n",
    "    if old == list(new)[0]:\n",
    "        unique_counter += 1\n",
    "    else:\n",
    "        diff_counter += 1\n",
    "print(\"Unique mappings:\", unique_counter)\n",
    "print(\"Different mappings:\", diff_counter)"
   ],
   "id": "b4b9712251295dfd",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique mappings: 4341\n",
      "Different mappings: 553\n"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-24T02:30:34.384179Z",
     "start_time": "2024-11-24T02:30:30.964676Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# make a copy of flow\n",
    "flow_final = flow.copy()\n",
    "\n",
    "flow_final['geoid_o'] = flow_final['new_geoid_o'].astype(str)\n",
    "flow_final['geoid_d'] = flow_final['new_geoid_d'].astype(str)\n",
    "\n",
    "flow_final.drop(columns=['new_geoid_o', 'new_geoid_d'], inplace=True)\n",
    "\n",
    "flow_final['geoid_o'] = flow_final['geoid_o'].astype(str)\n",
    "flow_final['geoid_d'] = flow_final['geoid_d'].astype(str)\n",
    "\n",
    "flow_final.to_csv('../flow.csv', index=False)\n",
    "\n",
    "print(\"Transformation complete! The new file is saved as 'flow.csv'.\")"
   ],
   "id": "8c785722124372ec",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformation complete! The new file is saved as 'flow.csv'.\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 4. Convert the boundary shapefile to boundary.geojson",
   "id": "1969ccdaa2f07244"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-23T23:14:34.140219Z",
     "start_time": "2024-11-23T23:14:33.289156Z"
    }
   },
   "cell_type": "code",
   "source": [
    "shapefile_path = \"tl_2020_36_puma20/tl_2020_36_puma20.shp\"\n",
    "tessellation = gpd.read_file(shapefile_path)\n",
    "\n",
    "geojson_path = \"tl_2020_36_puma20.geojson\"\n",
    "tessellation.to_file(geojson_path, driver=\"GeoJSON\")\n",
    "\n",
    "print(f\"GeoJSON file saved at {geojson_path}\")"
   ],
   "id": "55293ea02413394a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GeoJSON file saved at tl_2020_36_puma20.geojson\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-23T23:14:34.155541Z",
     "start_time": "2024-11-23T23:14:34.143021Z"
    }
   },
   "cell_type": "code",
   "source": [
    "source = \"tl_2020_36_puma20.geojson\"\n",
    "destination = \"../boundary.geojson\"\n",
    "shutil.copy(source, destination)\n",
    "\n",
    "print(f\"Tessellation copied from {source} to {destination}\")"
   ],
   "id": "85f491524285c953",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tessellation copied from tl_2020_36_puma20.geojson to ../boundary.geojson\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 5. Add total population to aggregated_features.csv and save it as features.csv",
   "id": "3cd5746d73893dca"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-04T07:14:23.677609Z",
     "start_time": "2024-12-04T07:14:23.591451Z"
    }
   },
   "cell_type": "code",
   "source": [
    "population_df = pd.read_csv('population.csv')\n",
    "features_df = pd.read_csv('aggregated_features.csv')\n",
    "\n",
    "merged_df = features_df.merge(population_df[['geoid', 'total_population']], left_on='GEOID', right_on='geoid', how='left')\n",
    "merged_df = merged_df.drop(columns=['geoid'])\n",
    "merged_df = merged_df.rename(columns={'GEOID': 'geoid'})\n",
    "\n",
    "output_path = '../features.csv'\n",
    "merged_df.to_csv(output_path, index=False)\n",
    "print(f\"Features data saved to {output_path}\")"
   ],
   "id": "15d03f9d728c3122",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features data saved to ../features.csv\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "e51c173700f838d"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
